{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"541-srgan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I0BP4w-L9m-1","executionInfo":{"status":"ok","timestamp":1652091908559,"user_tz":420,"elapsed":26481,"user":{"displayName":"Amrith Coumaran","userId":"13285433589567735179"}},"outputId":"9d2a267d-746f-4c8b-af1e-8554cbfffd68"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import sys\n","py_file_location = \"/content/drive/My Drive/Image Super Resolution/SRGAN/\"\n","sys.path.append(os.path.abspath(py_file_location))\n","from dataset import DIV2KDataset\n","from model2 import Discriminator\n","from model2 import SRResNet\n","from loss import ContentLoss, TVLoss"],"metadata":{"id":"hYEQFkl_Alkq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","from enum import Enum\n","from copy import deepcopy\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.cuda import amp\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision.transforms as transform\n","from torchsummary import summary\n","from torchvision.transforms import functional as F\n","from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","from PIL import Image\n","from tqdm import tqdm\n","import cv2\n","import torch.backends.cudnn as cudnn\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","cudnn.benchmark = True"],"metadata":{"id":"iq369gHjAlna"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = DIV2KDataset(0)\n","train_dataloader = DataLoader(train_dataset, batch_size = 8, shuffle=True, num_workers=2, pin_memory=True)\n","\n","valid_dataset = DIV2KDataset(1)\n","valid_dataloader = DataLoader(valid_dataset,batch_size = 1, shuffle=False, num_workers=2, pin_memory=True)\n","\n","test_dataset = DIV2KDataset(2)\n","test_dataloader = DataLoader(test_dataset,batch_size = 1, shuffle=False, num_workers=2, pin_memory=True)"],"metadata":{"id":"V606Se15Alpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["srresnet_checkpoint = \"/content/drive/My Drive/Image Super Resolution/SRGAN/srresnet.pth.tar\"\n","generator = SRResNet().to(device)\n","checkpoint = torch.load(srresnet_checkpoint)\n","generator.load_state_dict(checkpoint['state_dict'])\n","generator = generator.to(device)\n","\n","discriminator = Discriminator().to(device)"],"metadata":{"id":"WdjgWMKMAlsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary(generator, (3, 128, 128))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMWp9HheSoxr","executionInfo":{"status":"ok","timestamp":1652040740180,"user_tz":420,"elapsed":700,"user":{"displayName":"Amrith Coumaran","userId":"13285433589567735179"}},"outputId":"0bbb12bc-b217-436f-b535-65306f3d9eaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 128, 128]          15,616\n","             PReLU-2         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-3         [-1, 64, 128, 128]               0\n","            Conv2d-4         [-1, 64, 128, 128]          36,928\n","       BatchNorm2d-5         [-1, 64, 128, 128]             128\n","             PReLU-6         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-7         [-1, 64, 128, 128]               0\n","            Conv2d-8         [-1, 64, 128, 128]          36,928\n","       BatchNorm2d-9         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-10         [-1, 64, 128, 128]               0\n","    ResidualBlock-11         [-1, 64, 128, 128]               0\n","           Conv2d-12         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-13         [-1, 64, 128, 128]             128\n","            PReLU-14         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-15         [-1, 64, 128, 128]               0\n","           Conv2d-16         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-17         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-18         [-1, 64, 128, 128]               0\n","    ResidualBlock-19         [-1, 64, 128, 128]               0\n","           Conv2d-20         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-21         [-1, 64, 128, 128]             128\n","            PReLU-22         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-23         [-1, 64, 128, 128]               0\n","           Conv2d-24         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-25         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-26         [-1, 64, 128, 128]               0\n","    ResidualBlock-27         [-1, 64, 128, 128]               0\n","           Conv2d-28         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-29         [-1, 64, 128, 128]             128\n","            PReLU-30         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-31         [-1, 64, 128, 128]               0\n","           Conv2d-32         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-33         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-34         [-1, 64, 128, 128]               0\n","    ResidualBlock-35         [-1, 64, 128, 128]               0\n","           Conv2d-36         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-37         [-1, 64, 128, 128]             128\n","            PReLU-38         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-39         [-1, 64, 128, 128]               0\n","           Conv2d-40         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-41         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-42         [-1, 64, 128, 128]               0\n","    ResidualBlock-43         [-1, 64, 128, 128]               0\n","           Conv2d-44         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-45         [-1, 64, 128, 128]             128\n","            PReLU-46         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-47         [-1, 64, 128, 128]               0\n","           Conv2d-48         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-49         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-50         [-1, 64, 128, 128]               0\n","    ResidualBlock-51         [-1, 64, 128, 128]               0\n","           Conv2d-52         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-53         [-1, 64, 128, 128]             128\n","            PReLU-54         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-55         [-1, 64, 128, 128]               0\n","           Conv2d-56         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-57         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-58         [-1, 64, 128, 128]               0\n","    ResidualBlock-59         [-1, 64, 128, 128]               0\n","           Conv2d-60         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-61         [-1, 64, 128, 128]             128\n","            PReLU-62         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-63         [-1, 64, 128, 128]               0\n","           Conv2d-64         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-65         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-66         [-1, 64, 128, 128]               0\n","    ResidualBlock-67         [-1, 64, 128, 128]               0\n","           Conv2d-68         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-69         [-1, 64, 128, 128]             128\n","            PReLU-70         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-71         [-1, 64, 128, 128]               0\n","           Conv2d-72         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-73         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-74         [-1, 64, 128, 128]               0\n","    ResidualBlock-75         [-1, 64, 128, 128]               0\n","           Conv2d-76         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-77         [-1, 64, 128, 128]             128\n","            PReLU-78         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-79         [-1, 64, 128, 128]               0\n","           Conv2d-80         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-81         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-82         [-1, 64, 128, 128]               0\n","    ResidualBlock-83         [-1, 64, 128, 128]               0\n","           Conv2d-84         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-85         [-1, 64, 128, 128]             128\n","            PReLU-86         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-87         [-1, 64, 128, 128]               0\n","           Conv2d-88         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-89         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-90         [-1, 64, 128, 128]               0\n","    ResidualBlock-91         [-1, 64, 128, 128]               0\n","           Conv2d-92         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-93         [-1, 64, 128, 128]             128\n","            PReLU-94         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-95         [-1, 64, 128, 128]               0\n","           Conv2d-96         [-1, 64, 128, 128]          36,928\n","      BatchNorm2d-97         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-98         [-1, 64, 128, 128]               0\n","    ResidualBlock-99         [-1, 64, 128, 128]               0\n","          Conv2d-100         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-101         [-1, 64, 128, 128]             128\n","           PReLU-102         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-103         [-1, 64, 128, 128]               0\n","          Conv2d-104         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-105         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-106         [-1, 64, 128, 128]               0\n","   ResidualBlock-107         [-1, 64, 128, 128]               0\n","          Conv2d-108         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-109         [-1, 64, 128, 128]             128\n","           PReLU-110         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-111         [-1, 64, 128, 128]               0\n","          Conv2d-112         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-113         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-114         [-1, 64, 128, 128]               0\n","   ResidualBlock-115         [-1, 64, 128, 128]               0\n","          Conv2d-116         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-117         [-1, 64, 128, 128]             128\n","           PReLU-118         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-119         [-1, 64, 128, 128]               0\n","          Conv2d-120         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-121         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-122         [-1, 64, 128, 128]               0\n","   ResidualBlock-123         [-1, 64, 128, 128]               0\n","          Conv2d-124         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-125         [-1, 64, 128, 128]             128\n","           PReLU-126         [-1, 64, 128, 128]               1\n","ConvolutionalBlock-127         [-1, 64, 128, 128]               0\n","          Conv2d-128         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-129         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-130         [-1, 64, 128, 128]               0\n","   ResidualBlock-131         [-1, 64, 128, 128]               0\n","          Conv2d-132         [-1, 64, 128, 128]          36,928\n","     BatchNorm2d-133         [-1, 64, 128, 128]             128\n","ConvolutionalBlock-134         [-1, 64, 128, 128]               0\n","          Conv2d-135        [-1, 256, 128, 128]         147,712\n","    PixelShuffle-136         [-1, 64, 256, 256]               0\n","           PReLU-137         [-1, 64, 256, 256]               1\n","SubPixelConvolutionalBlock-138         [-1, 64, 256, 256]               0\n","          Conv2d-139        [-1, 256, 256, 256]         147,712\n","    PixelShuffle-140         [-1, 64, 512, 512]               0\n","           PReLU-141         [-1, 64, 512, 512]               1\n","SubPixelConvolutionalBlock-142         [-1, 64, 512, 512]               0\n","          Conv2d-143          [-1, 3, 512, 512]          15,555\n","            Tanh-144          [-1, 3, 512, 512]               0\n","ConvolutionalBlock-145          [-1, 3, 512, 512]               0\n","================================================================\n","Total params: 1,549,462\n","Trainable params: 1,549,462\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.19\n","Forward/backward pass size (MB): 1730.00\n","Params size (MB): 5.91\n","Estimated Total Size (MB): 1736.10\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["summary(discriminator, (3, 512, 512))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRGU_r85SsCw","executionInfo":{"status":"ok","timestamp":1652040740828,"user_tz":420,"elapsed":656,"user":{"displayName":"Amrith Coumaran","userId":"13285433589567735179"}},"outputId":"83933790-31d3-428c-f149-54a573a7b588"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 512, 512]           1,792\n","         LeakyReLU-2         [-1, 64, 512, 512]               0\n","ConvolutionalBlock-3         [-1, 64, 512, 512]               0\n","            Conv2d-4         [-1, 64, 256, 256]          36,928\n","       BatchNorm2d-5         [-1, 64, 256, 256]             128\n","         LeakyReLU-6         [-1, 64, 256, 256]               0\n","ConvolutionalBlock-7         [-1, 64, 256, 256]               0\n","            Conv2d-8        [-1, 128, 256, 256]          73,856\n","       BatchNorm2d-9        [-1, 128, 256, 256]             256\n","        LeakyReLU-10        [-1, 128, 256, 256]               0\n","ConvolutionalBlock-11        [-1, 128, 256, 256]               0\n","           Conv2d-12        [-1, 128, 128, 128]         147,584\n","      BatchNorm2d-13        [-1, 128, 128, 128]             256\n","        LeakyReLU-14        [-1, 128, 128, 128]               0\n","ConvolutionalBlock-15        [-1, 128, 128, 128]               0\n","           Conv2d-16        [-1, 256, 128, 128]         295,168\n","      BatchNorm2d-17        [-1, 256, 128, 128]             512\n","        LeakyReLU-18        [-1, 256, 128, 128]               0\n","ConvolutionalBlock-19        [-1, 256, 128, 128]               0\n","           Conv2d-20          [-1, 256, 64, 64]         590,080\n","      BatchNorm2d-21          [-1, 256, 64, 64]             512\n","        LeakyReLU-22          [-1, 256, 64, 64]               0\n","ConvolutionalBlock-23          [-1, 256, 64, 64]               0\n","           Conv2d-24          [-1, 512, 64, 64]       1,180,160\n","      BatchNorm2d-25          [-1, 512, 64, 64]           1,024\n","        LeakyReLU-26          [-1, 512, 64, 64]               0\n","ConvolutionalBlock-27          [-1, 512, 64, 64]               0\n","           Conv2d-28          [-1, 512, 32, 32]       2,359,808\n","      BatchNorm2d-29          [-1, 512, 32, 32]           1,024\n","        LeakyReLU-30          [-1, 512, 32, 32]               0\n","ConvolutionalBlock-31          [-1, 512, 32, 32]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 6, 6]               0\n","           Linear-33                 [-1, 1024]      18,875,392\n","        LeakyReLU-34                 [-1, 1024]               0\n","           Linear-35                    [-1, 1]           1,025\n","================================================================\n","Total params: 23,565,505\n","Trainable params: 23,565,505\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 3.00\n","Forward/backward pass size (MB): 1072.16\n","Params size (MB): 89.90\n","Estimated Total Size (MB): 1165.05\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["def init_weights(model):\n","  if isinstance(model, torch.nn.Linear) or isinstance(model, torch.nn.Conv2d):\n","    torch.nn.init.xavier_uniform_(model.weight)\n","\n","\n","discriminator.apply(init_weights)"],"metadata":{"id":"MtWLCMfzJ76B","executionInfo":{"status":"ok","timestamp":1652040740831,"user_tz":420,"elapsed":30,"user":{"displayName":"Amrith Coumaran","userId":"13285433589567735179"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd763e7c-2fa2-4a3b-c5d8-e0a9043a10df"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discriminator(\n","  (conv_blocks): Sequential(\n","    (0): ConvolutionalBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (1): ConvolutionalBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (2): ConvolutionalBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (3): ConvolutionalBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (4): ConvolutionalBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (5): ConvolutionalBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (6): ConvolutionalBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (7): ConvolutionalBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","  )\n","  (adaptive_pool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (fc1): Linear(in_features=18432, out_features=1024, bias=True)\n","  (leaky_relu): LeakyReLU(negative_slope=0.2)\n","  (fc2): Linear(in_features=1024, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["g_optimizer = torch.optim.Adam(generator.parameters(),lr=1e-4)\n","d_optimizer = torch.optim.Adam(discriminator.parameters(),lr=1e-4)"],"metadata":{"id":"oii9HVpxA6dC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["content_criterion = ContentLoss().to(device)\n","adversarial_criterion = nn.BCEWithLogitsLoss().to(device)\n","criterion = nn.MSELoss().to(device)\n","TVLoss = TVLoss().to(device)"],"metadata":{"id":"o1E5pcqDA0aq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 50\n","\n","d_scheduler = lr_scheduler.StepLR(d_optimizer, epochs // 4, 0.1) \n","g_scheduler = lr_scheduler.StepLR(g_optimizer, epochs // 4, 0.1)\n","\n","scaler = amp.GradScaler()"],"metadata":{"id":"ZYemY2DJA0da"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.transforms import transforms\n","def validate(model, loader): \n","\n","  output_dir = \"/content/drive/My Drive/Image Super Resolution/SRGAN/output_srgan/\"\n","  img_idx = 0\n","\n","  with torch.no_grad():\n","    model.eval()\n","    psnr = 0\n","    ssim = 0\n","    val_loss= 0\n","    with tqdm(loader, unit='images') as validation:\n","      validation.set_description(\"Validation\")\n","      for lr_batch, hr_batch in validation:\n","        img_idx += 1\n","        hr_img, lr_img = hr_batch.to(device), lr_batch.to(device)\n","        with amp.autocast():\n","          hr_pred = model(lr_img).clamp(0.0,1.0).to(device)\n","\n","        hr_pred_img = hr_pred.squeeze_(0).permute(1, 2, 0).mul_(255).clamp_(0, 255).cpu().numpy().astype(\"uint8\")\n","        hr_pred_img = hr_pred_img.astype(np.float32)\n","        hr_y_image = np.dot(hr_pred_img, [65.481, 128.553, 24.966]) + 16.0\n","        hr_y_image /= 255.\n","        hr_y_image = hr_y_image.astype(np.float32)\n","\n","        hr_gt_img = hr_img.squeeze_(0).permute(1, 2, 0).mul_(255).clamp_(0, 255).cpu().numpy().astype(\"uint8\")\n","        hr_gt_img = hr_gt_img.astype(np.float32)\n","        hr_gt_y_image = np.dot(hr_gt_img, [65.481, 128.553, 24.966]) + 16.0\n","        hr_gt_y_image /= 255.\n","        hr_gt_y_image = hr_gt_y_image.astype(np.float32)\n","\n","        psnr += peak_signal_noise_ratio(hr_gt_img, hr_pred_img,data_range=255.) / len(loader)\n","        ssim += structural_similarity(hr_gt_img, hr_pred_img,data_range=255., multichannel= True) / len(loader)\n","\n","        validation.set_postfix(Val_PSNR = psnr, Val_SSIM = ssim)\n","\n","        with amp.autocast():\n","          hr_pred = model(lr_img).clamp(0.0, 1.0).to(device)\n","\n","        hr_pred_img = hr_pred.squeeze(0).cpu().numpy()\n","        image = hr_pred_img.transpose((1,2,0))\n","        img = (image * 255.).astype(\"uint8\")\n","        path = output_dir + str(img_idx) + '.jpg'\n","        cv2.imwrite(path, img)\n","   \n","    return psnr, ssim\n","\n","#validate(generator,valid_dataloader)\n"],"metadata":{"id":"JAOOs1CnEB6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.transforms import transforms\n","def test(model, loader): \n","  img_idx = 0\n","\n","  with torch.no_grad():\n","    model.eval()\n","    psnr = 0\n","    ssim = 0\n","    test_loss= 0\n","    with tqdm(loader, unit='images') as validation:\n","      validation.set_description(\"Validation\")\n","      for lr_batch, hr_batch in validation:\n","        img_idx += 1\n","        hr_img, lr_img = hr_batch.to(device), lr_batch.to(device)\n","        with amp.autocast():\n","          hr_pred = model(lr_img)\n","          prob_real = discriminator(hr_img)\n","          prob_fake = discriminator(hr_pred)\n","\n","          real_labels = torch.ones(prob_real.size()).to(device)\n","          fake_labels = torch.zeros(prob_fake.size()).to(device)\n","\n","          g_loss_bce_real = adversarial_criterion(prob_real, real_labels)\n","          g_loss_bce_fake = adversarial_criterion(prob_fake, fake_labels)\n","\n","          g_loss_ad = (g_loss_bce_real + g_loss_bce_fake).mean()\n","          g_loss_content = content_criterion(hr_pred, hr_img)     \n","          #g_loss_tv = TVLoss(hr_pred)       \n","          g_loss = g_loss_content + (0.001 * g_loss_ad) #+ (2e-8 * g_loss_tv)\n","          test_loss += g_loss.item() / len(loader)\n","\n","        hr_pred_img = hr_pred.squeeze_(0).permute(1, 2, 0).mul_(255).clamp_(0, 255).cpu().numpy().astype(\"uint8\")\n","        hr_pred_img = hr_pred_img.astype(np.float32)\n","        hr_y_image = np.dot(hr_pred_img, [65.481, 128.553, 24.966]) + 16.0\n","        hr_y_image /= 255.\n","        hr_y_image = hr_y_image.astype(np.float32)\n","\n","        hr_gt_img = hr_img.squeeze_(0).permute(1, 2, 0).mul_(255).clamp_(0, 255).cpu().numpy().astype(\"uint8\")\n","        hr_gt_img = hr_gt_img.astype(np.float32)\n","        hr_gt_y_image = np.dot(hr_gt_img, [65.481, 128.553, 24.966]) + 16.0\n","        hr_gt_y_image /= 255.\n","        hr_gt_y_image = hr_gt_y_image.astype(np.float32)\n","\n","        psnr += peak_signal_noise_ratio(hr_gt_img, hr_pred_img,data_range=255.) / len(loader)\n","        ssim += structural_similarity(hr_gt_img, hr_pred_img,data_range=255., multichannel= True) / len(loader)\n","\n","        validation.set_postfix(Val_PSNR = psnr, Val_SSIM = ssim)\n","\n","        with amp.autocast():\n","          hr_pred = model(lr_img).clamp(0.0, 1.0).to(device)\n","\n","        hr_pred_img = hr_pred.squeeze(0).cpu().numpy()\n","        image = hr_pred_img.transpose((1,2,0))\n","        img = (image * 255.).astype(\"uint8\")\n","        path = output_dir + str(img_idx) + '.jpg'\n","        #cv2.imwrite(path, img)\n","   \n","    return test_loss, psnr, ssim\n","\n","  checkpoint = torch.load(PATH)\n","\n","output_dir = \"/content/drive/My Drive/Image Super Resolution/SRGAN/srresnet-models/model3/test/\"\n","#test(model,test_dataloader)\n","# test(model,valid_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clOeks6NuicG","executionInfo":{"status":"ok","timestamp":1652092758024,"user_tz":420,"elapsed":102676,"user":{"displayName":"Amrith Coumaran","userId":"13285433589567735179"}},"outputId":"a9113657-91b9-428c-efa7-bcda6d8ac28a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 200/200 [01:41<00:00,  1.96images/s, Val_PSNR=24.5, Val_SSIM=0.718]\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.004507378927519311, 24.480883341851435, 0.7175038347075701)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["resume_training = True\n","epochs = 50\n","PATH_G = \"/content/drive/My Drive/Image Super Resolution/SRGAN/g_model.pth.tar\"\n","PATH_D = \"/content/drive/My Drive/Image Super Resolution/SRGAN/d_model.pth.tar\"\n","\n","d_loss_list = list()\n","g_loss_list = list()\n","psnr_list = list()\n","\n","val_ssim_list = list()\n","val_psnr_list = list()\n","val_loss_list = list()\n","\n","prev_epoch = 0\n","\n","if resume_training and os.path.exists(PATH_G) and os.path.exists(PATH_D):\n","\n","  checkpoint_G = torch.load(PATH_G)\n","  checkpoint_D = torch.load(PATH_D)\n","\n","  generator.load_state_dict(checkpoint_G['state_dict'])\n","  g_optimizer.load_state_dict(checkpoint_G['optimizer'])\n","  g_scheduler.load_state_dict(checkpoint_G['scheduler'])\n","\n","  discriminator.load_state_dict(checkpoint_D['state_dict'])\n","  d_optimizer.load_state_dict(checkpoint_D['optimizer'])\n","  d_scheduler.load_state_dict(checkpoint_D['scheduler'])\n"," \n","  prev_epoch = deepcopy(checkpoint_G['epoch'])\n","  d_loss_list = deepcopy(checkpoint_D['train_loss_list'])\n","  g_loss_list = deepcopy(checkpoint_G['train_loss_list'])\n","  psnr_list = deepcopy(checkpoint_G['psnr_list'])\n","\n","  val_ssim_list = deepcopy(checkpoint_G['val_ssim_list'])\n","  val_psnr_list = deepcopy(checkpoint_G['val_psnr_list'])\n","  val_loss_list = deepcopy(checkpoint_G['val_loss_list'])\n"," \n","  print(\"Continue training from previous checkpoints ...\")\n","  \n","\n","for epoch in range(prev_epoch, epochs):\n","  start = time.time()\n","  epoch_d_loss = 0\n","  epoch_g_loss = 0\n","  epoch_psnr = 0\n","  \n","  discriminator.train()\n","  generator.train()\n","  with tqdm(train_dataloader, unit='batch') as tepoch:\n","    tepoch.set_description(f\"Epoch {epoch+1:4d}/{epochs}\")\n","\n","    for lr_batch, hr_batch in tepoch:\n","        hr_img, lr_img = hr_batch.to(device), lr_batch.to(device)\n","        \n","        d_optimizer.zero_grad()\n","\n","        for p in discriminator.parameters():\n","          p.requires_grad = True\n","\n","        fake_hr = generator(lr_img)\n","\n","        with amp.autocast():\n","          prob_real = discriminator(hr_img)\n","          prob_fake =  discriminator(fake_hr.detach())\n","\n","          real_labels = torch.ones(prob_real.size()).to(device)\n","          fake_labels = torch.zeros(prob_fake.size()).to(device)\n","\n","          d_loss_real = adversarial_criterion(prob_real, real_labels)\n","          d_loss_fake = adversarial_criterion(prob_fake, fake_labels)\n","\n","        scaler.scale(d_loss_real).backward()\n","        scaler.scale(d_loss_fake).backward()\n","        scaler.step(d_optimizer)\n","        scaler.update()\n","        d_loss = (d_loss_real + d_loss_fake) \n","        epoch_d_loss += d_loss / len(train_dataloader)\n","\n","        for p in discriminator.parameters():\n","          p.requires_grad = False\n","\n","        g_optimizer.zero_grad()\n","        \n","        with amp.autocast():\n","          prob_real = discriminator(hr_img)\n","          prob_fake = discriminator(fake_hr)\n","\n","          real_labels = torch.ones(prob_real.size()).to(device)\n","          fake_labels = torch.zeros(prob_fake.size()).to(device)\n","\n","          g_loss_bce_real = adversarial_criterion(prob_real, real_labels)\n","          g_loss_bce_fake = adversarial_criterion(prob_fake, fake_labels)\n","\n","          g_loss_ad = (g_loss_bce_real + g_loss_bce_fake).mean()\n","          g_loss_content = content_criterion(fake_hr, hr_img)     \n","          g_loss_tv = TVLoss(fake_hr)       \n","          g_loss = g_loss_content + (0.001 * g_loss_ad) + (2e-8 * g_loss_tv)\n","\n","        scaler.scale(g_loss).backward()\n","        scaler.step(g_optimizer)\n","        scaler.update()\n","        epoch_g_loss += g_loss / len(train_dataloader)\n","\n","\n","        tepoch.set_postfix(D_Loss = epoch_d_loss.item(), G_Loss = epoch_g_loss.item())\n","    \n","    val_psnr, val_ssim = validate(generator,valid_dataloader)\n","    print('\\n')\n","    torch.cuda.empty_cache()\n","    \n","    val_psnr_list.append(val_psnr)\n","    val_ssim_list.append(val_ssim)\n","\n","    d_loss_list.append(epoch_d_loss.item())\n","    g_loss_list.append(epoch_g_loss.item())\n","    psnr_list.append(epoch_psnr)\n","\n","    d_scheduler.step()\n","    g_scheduler.step()\n","\n","    torch.save({\"epoch\": epoch + 1,\n","              \"psnr_list\": psnr_list,\n","              \"state_dict\": discriminator.state_dict(),\n","              \"optimizer\": d_optimizer.state_dict(),\n","              \"scheduler\": d_scheduler.state_dict(),\n","              \"train_loss_list\": d_loss_list,\n","              \"val_loss_list\": val_loss_list,\n","              \"val_ssim_list\": val_ssim_list,\n","              \"val_psnr_list\": val_psnr_list}, PATH_D)\n","    \n","    torch.save({\"epoch\": epoch + 1,\n","              \"psnr_list\": psnr_list,\n","              \"state_dict\": generator.state_dict(),\n","              \"optimizer\": g_optimizer.state_dict(),\n","              \"scheduler\": g_scheduler.state_dict(),\n","              \"train_loss_list\": g_loss_list,\n","              \"val_loss_list\": val_loss_list,\n","              \"val_ssim_list\": val_ssim_list,\n","              \"val_psnr_list\": val_psnr_list}, PATH_G)"],"metadata":{"id":"_3Kn2AH2A0ia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot(PATH_G, PATH_D, generator, discriminator):\n","  checkpoint_G = torch.load(PATH_G)\n","  checkpoint_D = torch.load(PATH_D)\n","\n","  prev_epoch = deepcopy(checkpoint_G['epoch'])\n","  d_loss_list = deepcopy(checkpoint_D['train_loss_list'])\n","  g_loss_list = deepcopy(checkpoint_G['train_loss_list'])\n","\n","  val_ssim_list = deepcopy(checkpoint_G['val_ssim_list'])\n","  val_psnr_list = deepcopy(checkpoint_G['val_psnr_list'])\n","  val_loss_list = deepcopy(checkpoint_G['val_loss_list'])\n","\n","  print(len(d_loss_list), len(g_loss_list), len(val_ssim_list), len(val_psnr_list),len(val_loss_list))\n","  print(val_loss_list)\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(\"Training Loss\")\n","  plt.title(\"Training Loss\")\n","  plt.plot(d_loss_list, label = 'Discriminator')\n","  # plt.show()\n","  # print(\"\\n\")  \n","  # plt.xlabel(\"Epochs\")\n","  # plt.ylabel(\"Training Loss\")\n","  # plt.title(\"Generator Training Loss\")\n","  plt.plot(g_loss_list, label = 'Generator')\n","  #plt.plot(val_loss_list, label = 'Validation Loss')\n","  plt.legend()\n","  plt.show()\n","  print(\"\\n\") \n","\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(\"PSNR\")\n","  plt.title(\"Validation PSNR\")\n","  val_psnr_list = np.array(val_psnr_list)\n","  plt.plot(val_psnr_list[10:])\n","  plt.show()\n","  print(\"\\n\") \n","\n","\n","def plot_srresnet(PATH, model):\n","  checkpoint = torch.load(PATH)\n","\n","  loss_list = deepcopy(checkpoint['train_loss_list'])\n","\n","  val_ssim_list = deepcopy(checkpoint['val_ssim_list'])\n","  val_psnr_list = deepcopy(checkpoint['val_psnr_list'])\n","  val_loss_list = deepcopy(checkpoint['val_loss_list'])\n","  print(loss_list)\n","\n","\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(\"Loss\")\n","  plt.title(\"SRResNet Loss\")\n","  plt.plot(loss_list, label = 'Training')\n","  plt.plot(val_loss_list, label = 'Validation')\n","  plt.legend()\n","  plt.show()\n","  print(\"\\n\") \n","\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(\"PSNR\")\n","  plt.title(\"Validation PSNR\")\n","  plt.plot(val_psnr_list)\n","  plt.show()\n","  print(\"\\n\") "],"metadata":{"id":"roVbY2D8gKT5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PATH_G = \"/content/drive/My Drive/Image Super Resolution/SRGAN/srgan-models/model3/g_model.pth.tar\"\n","# PATH_D = \"/content/drive/My Drive/Image Super Resolution/SRGAN/srgan-models/model3/d_model.pth.tar\"\n","\n","# plot(PATH_G, PATH_D, model, discriminator)"],"metadata":{"id":"W8Wnr7CNRupK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = SRResNet().to(device)\n","# PATH = \"/content/drive/My Drive/Image Super Resolution/SRGAN/srresnet.pth.tar\"\n","# plot_srresnet(PATH, model)"],"metadata":{"id":"3xCJPThnSqhz"},"execution_count":null,"outputs":[]}]}